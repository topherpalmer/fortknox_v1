{"ast":null,"code":"import { Amplify } from '@aws-amplify/core';\nimport { StorageAction } from '@aws-amplify/core/internals/utils';\nimport '@smithy/md5-js';\nimport '@aws-amplify/core/internals/aws-client-utils';\nimport '../../../utils/client/runtime/s3TransferHandler/fetch.mjs';\nimport 'fast-xml-parser';\nimport '../../../utils/client/runtime/s3TransferHandler/xhr.mjs';\nimport 'buffer';\nimport { StorageError } from '../../../../../errors/StorageError.mjs';\nimport { resolveS3ConfigAndInput } from '../../../utils/resolveS3ConfigAndInput.mjs';\nimport { CanceledError } from '../../../../../errors/CanceledError.mjs';\nimport '../../../../../errors/types/validation.mjs';\nimport { logger } from '../../../../../utils/logger.mjs';\nimport { validateStorageOperationInput } from '../../../utils/validateStorageOperationInput.mjs';\nimport { STORAGE_INPUT_KEY, DEFAULT_QUEUE_SIZE, DEFAULT_ACCESS_LEVEL } from '../../../utils/constants.mjs';\nimport '../../../utils/client/base.mjs';\nimport '../../../utils/client/getObject.mjs';\nimport '../../../utils/client/listObjectsV2.mjs';\nimport '../../../utils/client/putObject.mjs';\nimport '../../../utils/client/createMultipartUpload.mjs';\nimport '../../../utils/client/uploadPart.mjs';\nimport { completeMultipartUpload } from '../../../utils/client/completeMultipartUpload.mjs';\nimport '../../../utils/client/listParts.mjs';\nimport { abortMultipartUpload } from '../../../utils/client/abortMultipartUpload.mjs';\nimport '../../../utils/client/copyObject.mjs';\nimport { headObject } from '../../../utils/client/headObject.mjs';\nimport '../../../utils/client/deleteObject.mjs';\nimport { getStorageUserAgentValue } from '../../../utils/userAgent.mjs';\nimport { uploadPartExecutor } from './uploadPartExecutor.mjs';\nimport { getUploadsCacheKey, removeCachedUpload } from './uploadCache.mjs';\nimport { getConcurrentUploadsProgressTracker } from './progressTracker.mjs';\nimport { loadOrCreateMultipartUpload } from './initialUpload.mjs';\nimport { getDataChunker } from './getDataChunker.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Create closure hiding the multipart upload implementation details and expose the upload job and control functions(\n * onPause, onResume, onCancel).\n *\n * @internal\n */\nconst getMultipartUploadHandlers = (uploadDataInput, size) => {\n  let resolveCallback;\n  let rejectCallback;\n  let inProgressUpload;\n  let resolvedS3Config;\n  let abortController;\n  let resolvedAccessLevel;\n  let resolvedBucket;\n  let resolvedKeyPrefix;\n  let resolvedIdentityId;\n  let uploadCacheKey;\n  let finalKey;\n  // Special flag that differentiates HTTP requests abort error caused by pause() from ones caused by cancel().\n  // The former one should NOT cause the upload job to throw, but cancels any pending HTTP requests.\n  // This should be replaced by a special abort reason. However,the support of this API is lagged behind.\n  let isAbortSignalFromPause = false;\n  const startUpload = async () => {\n    const {\n      options: uploadDataOptions,\n      data\n    } = uploadDataInput;\n    const resolvedS3Options = await resolveS3ConfigAndInput(Amplify, uploadDataOptions);\n    abortController = new AbortController();\n    isAbortSignalFromPause = false;\n    resolvedS3Config = resolvedS3Options.s3Config;\n    resolvedBucket = resolvedS3Options.bucket;\n    resolvedIdentityId = resolvedS3Options.identityId;\n    const {\n      inputType,\n      objectKey\n    } = validateStorageOperationInput(uploadDataInput, resolvedIdentityId);\n    const {\n      contentDisposition,\n      contentEncoding,\n      contentType = 'application/octet-stream',\n      metadata,\n      onProgress\n    } = uploadDataOptions ?? {};\n    finalKey = objectKey;\n    // Resolve \"key\" specific options\n    if (inputType === STORAGE_INPUT_KEY) {\n      const accessLevel = uploadDataOptions?.accessLevel;\n      resolvedKeyPrefix = resolvedS3Options.keyPrefix;\n      finalKey = resolvedKeyPrefix + objectKey;\n      resolvedAccessLevel = resolveAccessLevel(accessLevel);\n    }\n    if (!inProgressUpload) {\n      const {\n        uploadId,\n        cachedParts\n      } = await loadOrCreateMultipartUpload({\n        s3Config: resolvedS3Config,\n        accessLevel: resolvedAccessLevel,\n        bucket: resolvedBucket,\n        keyPrefix: resolvedKeyPrefix,\n        key: objectKey,\n        contentType,\n        contentDisposition,\n        contentEncoding,\n        metadata,\n        data,\n        size,\n        abortSignal: abortController.signal\n      });\n      inProgressUpload = {\n        uploadId,\n        completedParts: cachedParts\n      };\n    }\n    uploadCacheKey = size ? getUploadsCacheKey({\n      file: data instanceof File ? data : undefined,\n      accessLevel: resolvedAccessLevel,\n      contentType: uploadDataOptions?.contentType,\n      bucket: resolvedBucket,\n      size,\n      key: objectKey\n    }) : undefined;\n    const dataChunker = getDataChunker(data, size);\n    const completedPartNumberSet = new Set(inProgressUpload.completedParts.map(({\n      PartNumber\n    }) => PartNumber));\n    const onPartUploadCompletion = (partNumber, eTag) => {\n      inProgressUpload?.completedParts.push({\n        PartNumber: partNumber,\n        ETag: eTag\n      });\n    };\n    const concurrentUploadsProgressTracker = getConcurrentUploadsProgressTracker({\n      size,\n      onProgress\n    });\n    const concurrentUploadPartExecutors = [];\n    for (let index = 0; index < DEFAULT_QUEUE_SIZE; index++) {\n      concurrentUploadPartExecutors.push(uploadPartExecutor({\n        dataChunkerGenerator: dataChunker,\n        completedPartNumberSet,\n        s3Config: resolvedS3Config,\n        abortSignal: abortController.signal,\n        bucket: resolvedBucket,\n        finalKey,\n        uploadId: inProgressUpload.uploadId,\n        onPartUploadCompletion,\n        onProgress: concurrentUploadsProgressTracker.getOnProgressListener(),\n        isObjectLockEnabled: resolvedS3Options.isObjectLockEnabled\n      }));\n    }\n    await Promise.all(concurrentUploadPartExecutors);\n    const {\n      ETag: eTag\n    } = await completeMultipartUpload({\n      ...resolvedS3Config,\n      abortSignal: abortController.signal,\n      userAgentValue: getStorageUserAgentValue(StorageAction.UploadData)\n    }, {\n      Bucket: resolvedBucket,\n      Key: finalKey,\n      UploadId: inProgressUpload.uploadId,\n      MultipartUpload: {\n        Parts: inProgressUpload.completedParts.sort((partA, partB) => partA.PartNumber - partB.PartNumber)\n      }\n    });\n    if (size) {\n      const {\n        ContentLength: uploadedObjectSize\n      } = await headObject(resolvedS3Config, {\n        Bucket: resolvedBucket,\n        Key: finalKey\n      });\n      if (uploadedObjectSize && uploadedObjectSize !== size) {\n        throw new StorageError({\n          name: 'Error',\n          message: `Upload failed. Expected object size ${size}, but got ${uploadedObjectSize}.`\n        });\n      }\n    }\n    if (uploadCacheKey) {\n      await removeCachedUpload(uploadCacheKey);\n    }\n    const result = {\n      eTag,\n      contentType,\n      metadata\n    };\n    return inputType === STORAGE_INPUT_KEY ? {\n      key: objectKey,\n      ...result\n    } : {\n      path: objectKey,\n      ...result\n    };\n  };\n  const startUploadWithResumability = () => startUpload().then(resolveCallback).catch(error => {\n    const abortSignal = abortController?.signal;\n    if (abortSignal?.aborted && isAbortSignalFromPause) {\n      logger.debug('upload paused.');\n    } else {\n      // Uncaught errors should be exposed to the users.\n      rejectCallback(error);\n    }\n  });\n  const multipartUploadJob = () => new Promise((resolve, reject) => {\n    resolveCallback = resolve;\n    rejectCallback = reject;\n    startUploadWithResumability();\n  });\n  const onPause = () => {\n    isAbortSignalFromPause = true;\n    abortController?.abort();\n  };\n  const onResume = () => {\n    startUploadWithResumability();\n  };\n  const onCancel = message => {\n    // 1. abort in-flight API requests\n    abortController?.abort(message);\n    const cancelUpload = async () => {\n      // 2. clear upload cache.\n      if (uploadCacheKey) {\n        await removeCachedUpload(uploadCacheKey);\n      }\n      // 3. clear multipart upload on server side.\n      await abortMultipartUpload(resolvedS3Config, {\n        Bucket: resolvedBucket,\n        Key: finalKey,\n        UploadId: inProgressUpload?.uploadId\n      });\n    };\n    cancelUpload().catch(e => {\n      logger.debug('error when cancelling upload task.', e);\n    });\n    rejectCallback(\n    // Internal error that should not be exposed to the users. They should use isCancelError() to check if\n    // the error is caused by cancel().\n    new CanceledError(message ? {\n      message\n    } : undefined));\n  };\n  return {\n    multipartUploadJob,\n    onPause,\n    onResume,\n    onCancel\n  };\n};\nconst resolveAccessLevel = accessLevel => accessLevel ?? Amplify.libraryOptions.Storage?.S3?.defaultAccessLevel ?? DEFAULT_ACCESS_LEVEL;\nexport { getMultipartUploadHandlers };","map":{"version":3,"names":["getMultipartUploadHandlers","uploadDataInput","size","resolveCallback","rejectCallback","inProgressUpload","resolvedS3Config","abortController","resolvedAccessLevel","resolvedBucket","resolvedKeyPrefix","resolvedIdentityId","uploadCacheKey","finalKey","isAbortSignalFromPause","startUpload","options","uploadDataOptions","data","resolvedS3Options","resolveS3ConfigAndInput","Amplify","AbortController","s3Config","bucket","identityId","inputType","objectKey","validateStorageOperationInput","contentDisposition","contentEncoding","contentType","metadata","onProgress","STORAGE_INPUT_KEY","accessLevel","keyPrefix","resolveAccessLevel","uploadId","cachedParts","loadOrCreateMultipartUpload","key","abortSignal","signal","completedParts","getUploadsCacheKey","file","File","undefined","dataChunker","getDataChunker","completedPartNumberSet","Set","map","PartNumber","onPartUploadCompletion","partNumber","eTag","push","ETag","concurrentUploadsProgressTracker","getConcurrentUploadsProgressTracker","concurrentUploadPartExecutors","index","DEFAULT_QUEUE_SIZE","uploadPartExecutor","dataChunkerGenerator","getOnProgressListener","isObjectLockEnabled","Promise","all","completeMultipartUpload","userAgentValue","getStorageUserAgentValue","StorageAction","UploadData","Bucket","Key","UploadId","MultipartUpload","Parts","sort","partA","partB","ContentLength","uploadedObjectSize","headObject","StorageError","name","message","removeCachedUpload","result","path","startUploadWithResumability","then","catch","error","aborted","logger","debug","multipartUploadJob","resolve","reject","onPause","abort","onResume","onCancel","cancelUpload","abortMultipartUpload","e","CanceledError","libraryOptions","Storage","S3","defaultAccessLevel","DEFAULT_ACCESS_LEVEL"],"sources":["/Users/cp/Documents/Documents - Christopherâ€™s MacBook Air/Development/React/fortknox_v1/node_modules/@aws-amplify/storage/src/providers/s3/apis/uploadData/multipart/uploadHandlers.ts"],"sourcesContent":["// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport { Amplify } from '@aws-amplify/core';\nimport { StorageAction } from '@aws-amplify/core/internals/utils';\nimport { resolveS3ConfigAndInput, validateStorageOperationInput, } from '../../../utils';\nimport { DEFAULT_ACCESS_LEVEL, DEFAULT_QUEUE_SIZE, STORAGE_INPUT_KEY, } from '../../../utils/constants';\nimport { StorageError } from '../../../../../errors/StorageError';\nimport { CanceledError } from '../../../../../errors/CanceledError';\nimport { abortMultipartUpload, completeMultipartUpload, headObject, } from '../../../utils/client';\nimport { getStorageUserAgentValue } from '../../../utils/userAgent';\nimport { logger } from '../../../../../utils';\nimport { uploadPartExecutor } from './uploadPartExecutor';\nimport { getUploadsCacheKey, removeCachedUpload } from './uploadCache';\nimport { getConcurrentUploadsProgressTracker } from './progressTracker';\nimport { loadOrCreateMultipartUpload } from './initialUpload';\nimport { getDataChunker } from './getDataChunker';\n/**\n * Create closure hiding the multipart upload implementation details and expose the upload job and control functions(\n * onPause, onResume, onCancel).\n *\n * @internal\n */\nexport const getMultipartUploadHandlers = (uploadDataInput, size) => {\n    let resolveCallback;\n    let rejectCallback;\n    let inProgressUpload;\n    let resolvedS3Config;\n    let abortController;\n    let resolvedAccessLevel;\n    let resolvedBucket;\n    let resolvedKeyPrefix;\n    let resolvedIdentityId;\n    let uploadCacheKey;\n    let finalKey;\n    // Special flag that differentiates HTTP requests abort error caused by pause() from ones caused by cancel().\n    // The former one should NOT cause the upload job to throw, but cancels any pending HTTP requests.\n    // This should be replaced by a special abort reason. However,the support of this API is lagged behind.\n    let isAbortSignalFromPause = false;\n    const startUpload = async () => {\n        const { options: uploadDataOptions, data } = uploadDataInput;\n        const resolvedS3Options = await resolveS3ConfigAndInput(Amplify, uploadDataOptions);\n        abortController = new AbortController();\n        isAbortSignalFromPause = false;\n        resolvedS3Config = resolvedS3Options.s3Config;\n        resolvedBucket = resolvedS3Options.bucket;\n        resolvedIdentityId = resolvedS3Options.identityId;\n        const { inputType, objectKey } = validateStorageOperationInput(uploadDataInput, resolvedIdentityId);\n        const { contentDisposition, contentEncoding, contentType = 'application/octet-stream', metadata, onProgress, } = uploadDataOptions ?? {};\n        finalKey = objectKey;\n        // Resolve \"key\" specific options\n        if (inputType === STORAGE_INPUT_KEY) {\n            const accessLevel = uploadDataOptions\n                ?.accessLevel;\n            resolvedKeyPrefix = resolvedS3Options.keyPrefix;\n            finalKey = resolvedKeyPrefix + objectKey;\n            resolvedAccessLevel = resolveAccessLevel(accessLevel);\n        }\n        if (!inProgressUpload) {\n            const { uploadId, cachedParts } = await loadOrCreateMultipartUpload({\n                s3Config: resolvedS3Config,\n                accessLevel: resolvedAccessLevel,\n                bucket: resolvedBucket,\n                keyPrefix: resolvedKeyPrefix,\n                key: objectKey,\n                contentType,\n                contentDisposition,\n                contentEncoding,\n                metadata,\n                data,\n                size,\n                abortSignal: abortController.signal,\n            });\n            inProgressUpload = {\n                uploadId,\n                completedParts: cachedParts,\n            };\n        }\n        uploadCacheKey = size\n            ? getUploadsCacheKey({\n                file: data instanceof File ? data : undefined,\n                accessLevel: resolvedAccessLevel,\n                contentType: uploadDataOptions?.contentType,\n                bucket: resolvedBucket,\n                size,\n                key: objectKey,\n            })\n            : undefined;\n        const dataChunker = getDataChunker(data, size);\n        const completedPartNumberSet = new Set(inProgressUpload.completedParts.map(({ PartNumber }) => PartNumber));\n        const onPartUploadCompletion = (partNumber, eTag) => {\n            inProgressUpload?.completedParts.push({\n                PartNumber: partNumber,\n                ETag: eTag,\n            });\n        };\n        const concurrentUploadsProgressTracker = getConcurrentUploadsProgressTracker({\n            size,\n            onProgress,\n        });\n        const concurrentUploadPartExecutors = [];\n        for (let index = 0; index < DEFAULT_QUEUE_SIZE; index++) {\n            concurrentUploadPartExecutors.push(uploadPartExecutor({\n                dataChunkerGenerator: dataChunker,\n                completedPartNumberSet,\n                s3Config: resolvedS3Config,\n                abortSignal: abortController.signal,\n                bucket: resolvedBucket,\n                finalKey,\n                uploadId: inProgressUpload.uploadId,\n                onPartUploadCompletion,\n                onProgress: concurrentUploadsProgressTracker.getOnProgressListener(),\n                isObjectLockEnabled: resolvedS3Options.isObjectLockEnabled,\n            }));\n        }\n        await Promise.all(concurrentUploadPartExecutors);\n        const { ETag: eTag } = await completeMultipartUpload({\n            ...resolvedS3Config,\n            abortSignal: abortController.signal,\n            userAgentValue: getStorageUserAgentValue(StorageAction.UploadData),\n        }, {\n            Bucket: resolvedBucket,\n            Key: finalKey,\n            UploadId: inProgressUpload.uploadId,\n            MultipartUpload: {\n                Parts: inProgressUpload.completedParts.sort((partA, partB) => partA.PartNumber - partB.PartNumber),\n            },\n        });\n        if (size) {\n            const { ContentLength: uploadedObjectSize } = await headObject(resolvedS3Config, {\n                Bucket: resolvedBucket,\n                Key: finalKey,\n            });\n            if (uploadedObjectSize && uploadedObjectSize !== size) {\n                throw new StorageError({\n                    name: 'Error',\n                    message: `Upload failed. Expected object size ${size}, but got ${uploadedObjectSize}.`,\n                });\n            }\n        }\n        if (uploadCacheKey) {\n            await removeCachedUpload(uploadCacheKey);\n        }\n        const result = {\n            eTag,\n            contentType,\n            metadata,\n        };\n        return inputType === STORAGE_INPUT_KEY\n            ? { key: objectKey, ...result }\n            : { path: objectKey, ...result };\n    };\n    const startUploadWithResumability = () => startUpload()\n        .then(resolveCallback)\n        .catch(error => {\n        const abortSignal = abortController?.signal;\n        if (abortSignal?.aborted && isAbortSignalFromPause) {\n            logger.debug('upload paused.');\n        }\n        else {\n            // Uncaught errors should be exposed to the users.\n            rejectCallback(error);\n        }\n    });\n    const multipartUploadJob = () => new Promise((resolve, reject) => {\n        resolveCallback = resolve;\n        rejectCallback = reject;\n        startUploadWithResumability();\n    });\n    const onPause = () => {\n        isAbortSignalFromPause = true;\n        abortController?.abort();\n    };\n    const onResume = () => {\n        startUploadWithResumability();\n    };\n    const onCancel = (message) => {\n        // 1. abort in-flight API requests\n        abortController?.abort(message);\n        const cancelUpload = async () => {\n            // 2. clear upload cache.\n            if (uploadCacheKey) {\n                await removeCachedUpload(uploadCacheKey);\n            }\n            // 3. clear multipart upload on server side.\n            await abortMultipartUpload(resolvedS3Config, {\n                Bucket: resolvedBucket,\n                Key: finalKey,\n                UploadId: inProgressUpload?.uploadId,\n            });\n        };\n        cancelUpload().catch(e => {\n            logger.debug('error when cancelling upload task.', e);\n        });\n        rejectCallback(\n        // Internal error that should not be exposed to the users. They should use isCancelError() to check if\n        // the error is caused by cancel().\n        new CanceledError(message ? { message } : undefined));\n    };\n    return {\n        multipartUploadJob,\n        onPause,\n        onResume,\n        onCancel,\n    };\n};\nconst resolveAccessLevel = (accessLevel) => accessLevel ??\n    Amplify.libraryOptions.Storage?.S3?.defaultAccessLevel ??\n    DEFAULT_ACCESS_LEVEL;\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AAeA;AACA;AACA;AACA;AACA;AACA;AACY,MAACA,0BAA0B,GAAGA,CAACC,eAAe,EAAEC,IAAI,KAAK;EACjE,IAAIC,eAAe;EACnB,IAAIC,cAAc;EAClB,IAAIC,gBAAgB;EACpB,IAAIC,gBAAgB;EACpB,IAAIC,eAAe;EACnB,IAAIC,mBAAmB;EACvB,IAAIC,cAAc;EAClB,IAAIC,iBAAiB;EACrB,IAAIC,kBAAkB;EACtB,IAAIC,cAAc;EAClB,IAAIC,QAAQ;EAChB;EACA;EACA;EACI,IAAIC,sBAAsB,GAAG,KAAK;EAClC,MAAMC,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC5B,MAAM;MAAEC,OAAO,EAAEC,iBAAiB;MAAEC;IAAI,CAAE,GAAGjB,eAAe;IAC5D,MAAMkB,iBAAiB,GAAG,MAAMC,uBAAuB,CAACC,OAAO,EAAEJ,iBAAiB,CAAC;IACnFV,eAAe,GAAG,IAAIe,eAAe,EAAE;IACvCR,sBAAsB,GAAG,KAAK;IAC9BR,gBAAgB,GAAGa,iBAAiB,CAACI,QAAQ;IAC7Cd,cAAc,GAAGU,iBAAiB,CAACK,MAAM;IACzCb,kBAAkB,GAAGQ,iBAAiB,CAACM,UAAU;IACjD,MAAM;MAAEC,SAAS;MAAEC;IAAS,CAAE,GAAGC,6BAA6B,CAAC3B,eAAe,EAAEU,kBAAkB,CAAC;IACnG,MAAM;MAAEkB,kBAAkB;MAAEC,eAAe;MAAEC,WAAW,GAAG,0BAA0B;MAAEC,QAAQ;MAAEC;IAAU,CAAG,GAAGhB,iBAAiB,IAAI,EAAE;IACxIJ,QAAQ,GAAGc,SAAS;IAC5B;IACQ,IAAID,SAAS,KAAKQ,iBAAiB,EAAE;MACjC,MAAMC,WAAW,GAAGlB,iBAAiB,EAC/BkB,WAAW;MACjBzB,iBAAiB,GAAGS,iBAAiB,CAACiB,SAAS;MAC/CvB,QAAQ,GAAGH,iBAAiB,GAAGiB,SAAS;MACxCnB,mBAAmB,GAAG6B,kBAAkB,CAACF,WAAW,CAAC;IACjE;IACQ,IAAI,CAAC9B,gBAAgB,EAAE;MACnB,MAAM;QAAEiC,QAAQ;QAAEC;MAAW,CAAE,GAAG,MAAMC,2BAA2B,CAAC;QAChEjB,QAAQ,EAAEjB,gBAAgB;QAC1B6B,WAAW,EAAE3B,mBAAmB;QAChCgB,MAAM,EAAEf,cAAc;QACtB2B,SAAS,EAAE1B,iBAAiB;QAC5B+B,GAAG,EAAEd,SAAS;QACdI,WAAW;QACXF,kBAAkB;QAClBC,eAAe;QACfE,QAAQ;QACRd,IAAI;QACJhB,IAAI;QACJwC,WAAW,EAAEnC,eAAe,CAACoC;MAC7C,CAAa,CAAC;MACFtC,gBAAgB,GAAG;QACfiC,QAAQ;QACRM,cAAc,EAAEL;MAChC,CAAa;IACb;IACQ3B,cAAc,GAAGV,IAAI,GACf2C,kBAAkB,CAAC;MACjBC,IAAI,EAAE5B,IAAI,YAAY6B,IAAI,GAAG7B,IAAI,GAAG8B,SAAS;MAC7Cb,WAAW,EAAE3B,mBAAmB;MAChCuB,WAAW,EAAEd,iBAAiB,EAAEc,WAAW;MAC3CP,MAAM,EAAEf,cAAc;MACtBP,IAAI;MACJuC,GAAG,EAAEd;IACrB,CAAa,CAAC,GACAqB,SAAS;IACf,MAAMC,WAAW,GAAGC,cAAc,CAAChC,IAAI,EAAEhB,IAAI,CAAC;IAC9C,MAAMiD,sBAAsB,GAAG,IAAIC,GAAG,CAAC/C,gBAAgB,CAACuC,cAAc,CAACS,GAAG,CAAC,CAAC;MAAEC;IAAU,CAAE,KAAKA,UAAU,CAAC,CAAC;IAC3G,MAAMC,sBAAsB,GAAGA,CAACC,UAAU,EAAEC,IAAI,KAAK;MACjDpD,gBAAgB,EAAEuC,cAAc,CAACc,IAAI,CAAC;QAClCJ,UAAU,EAAEE,UAAU;QACtBG,IAAI,EAAEF;MACtB,CAAa,CAAC;IACd,CAAS;IACD,MAAMG,gCAAgC,GAAGC,mCAAmC,CAAC;MACzE3D,IAAI;MACJ+B;IACZ,CAAS,CAAC;IACF,MAAM6B,6BAA6B,GAAG,EAAE;IACxC,KAAK,IAAIC,KAAK,GAAG,CAAC,EAAEA,KAAK,GAAGC,kBAAkB,EAAED,KAAK,EAAE,EAAE;MACrDD,6BAA6B,CAACJ,IAAI,CAACO,kBAAkB,CAAC;QAClDC,oBAAoB,EAAEjB,WAAW;QACjCE,sBAAsB;QACtB5B,QAAQ,EAAEjB,gBAAgB;QAC1BoC,WAAW,EAAEnC,eAAe,CAACoC,MAAM;QACnCnB,MAAM,EAAEf,cAAc;QACtBI,QAAQ;QACRyB,QAAQ,EAAEjC,gBAAgB,CAACiC,QAAQ;QACnCiB,sBAAsB;QACtBtB,UAAU,EAAE2B,gCAAgC,CAACO,qBAAqB,EAAE;QACpEC,mBAAmB,EAAEjD,iBAAiB,CAACiD;MACvD,CAAa,CAAC,CAAC;IACf;IACQ,MAAMC,OAAO,CAACC,GAAG,CAACR,6BAA6B,CAAC;IAChD,MAAM;MAAEH,IAAI,EAAEF;IAAI,CAAE,GAAG,MAAMc,uBAAuB,CAAC;MACjD,GAAGjE,gBAAgB;MACnBoC,WAAW,EAAEnC,eAAe,CAACoC,MAAM;MACnC6B,cAAc,EAAEC,wBAAwB,CAACC,aAAa,CAACC,UAAU;IAC7E,CAAS,EAAE;MACCC,MAAM,EAAEnE,cAAc;MACtBoE,GAAG,EAAEhE,QAAQ;MACbiE,QAAQ,EAAEzE,gBAAgB,CAACiC,QAAQ;MACnCyC,eAAe,EAAE;QACbC,KAAK,EAAE3E,gBAAgB,CAACuC,cAAc,CAACqC,IAAI,CAAC,CAACC,KAAK,EAAEC,KAAK,KAAKD,KAAK,CAAC5B,UAAU,GAAG6B,KAAK,CAAC7B,UAAU;MACjH;IACA,CAAS,CAAC;IACF,IAAIpD,IAAI,EAAE;MACN,MAAM;QAAEkF,aAAa,EAAEC;MAAkB,CAAE,GAAG,MAAMC,UAAU,CAAChF,gBAAgB,EAAE;QAC7EsE,MAAM,EAAEnE,cAAc;QACtBoE,GAAG,EAAEhE;MACrB,CAAa,CAAC;MACF,IAAIwE,kBAAkB,IAAIA,kBAAkB,KAAKnF,IAAI,EAAE;QACnD,MAAM,IAAIqF,YAAY,CAAC;UACnBC,IAAI,EAAE,OAAO;UACbC,OAAO,EAAG,uCAAsCvF,IAAK,aAAYmF,kBAAmB;QACxG,CAAiB,CAAC;MAClB;IACA;IACQ,IAAIzE,cAAc,EAAE;MAChB,MAAM8E,kBAAkB,CAAC9E,cAAc,CAAC;IACpD;IACQ,MAAM+E,MAAM,GAAG;MACXlC,IAAI;MACJ1B,WAAW;MACXC;IACZ,CAAS;IACD,OAAON,SAAS,KAAKQ,iBAAiB,GAChC;MAAEO,GAAG,EAAEd,SAAS;MAAE,GAAGgE;IAAM,CAAE,GAC7B;MAAEC,IAAI,EAAEjE,SAAS;MAAE,GAAGgE;IAAM,CAAE;EAC5C,CAAK;EACD,MAAME,2BAA2B,GAAGA,CAAA,KAAM9E,WAAW,EAAE,CAClD+E,IAAI,CAAC3F,eAAe,CAAC,CACrB4F,KAAK,CAACC,KAAK,IAAI;IAChB,MAAMtD,WAAW,GAAGnC,eAAe,EAAEoC,MAAM;IAC3C,IAAID,WAAW,EAAEuD,OAAO,IAAInF,sBAAsB,EAAE;MAChDoF,MAAM,CAACC,KAAK,CAAC,gBAAgB,CAAC;IAC1C,CAAS,MACI;MACb;MACY/F,cAAc,CAAC4F,KAAK,CAAC;IACjC;EACA,CAAK,CAAC;EACF,MAAMI,kBAAkB,GAAGA,CAAA,KAAM,IAAI/B,OAAO,CAAC,CAACgC,OAAO,EAAEC,MAAM,KAAK;IAC9DnG,eAAe,GAAGkG,OAAO;IACzBjG,cAAc,GAAGkG,MAAM;IACvBT,2BAA2B,EAAE;EACrC,CAAK,CAAC;EACF,MAAMU,OAAO,GAAGA,CAAA,KAAM;IAClBzF,sBAAsB,GAAG,IAAI;IAC7BP,eAAe,EAAEiG,KAAK,EAAE;EAChC,CAAK;EACD,MAAMC,QAAQ,GAAGA,CAAA,KAAM;IACnBZ,2BAA2B,EAAE;EACrC,CAAK;EACD,MAAMa,QAAQ,GAAIjB,OAAO,IAAK;IAClC;IACQlF,eAAe,EAAEiG,KAAK,CAACf,OAAO,CAAC;IAC/B,MAAMkB,YAAY,GAAG,MAAAA,CAAA,KAAY;MACzC;MACY,IAAI/F,cAAc,EAAE;QAChB,MAAM8E,kBAAkB,CAAC9E,cAAc,CAAC;MACxD;MACA;MACY,MAAMgG,oBAAoB,CAACtG,gBAAgB,EAAE;QACzCsE,MAAM,EAAEnE,cAAc;QACtBoE,GAAG,EAAEhE,QAAQ;QACbiE,QAAQ,EAAEzE,gBAAgB,EAAEiC;MAC5C,CAAa,CAAC;IACd,CAAS;IACDqE,YAAY,EAAE,CAACZ,KAAK,CAACc,CAAC,IAAI;MACtBX,MAAM,CAACC,KAAK,CAAC,oCAAoC,EAAEU,CAAC,CAAC;IACjE,CAAS,CAAC;IACFzG,cAAc;IACtB;IACA;IACQ,IAAI0G,aAAa,CAACrB,OAAO,GAAG;MAAEA;IAAO,CAAE,GAAGzC,SAAS,CAAC,CAAC;EAC7D,CAAK;EACD,OAAO;IACHoD,kBAAkB;IAClBG,OAAO;IACPE,QAAQ;IACRC;EACR,CAAK;AACL;AACA,MAAMrE,kBAAkB,GAAIF,WAAW,IAAKA,WAAW,IACnDd,OAAO,CAAC0F,cAAc,CAACC,OAAO,EAAEC,EAAE,EAAEC,kBAAkB,IACtDC,oBAAoB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}